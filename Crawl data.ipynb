{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5639358e",
   "metadata": {},
   "source": [
    "Pipeline kéo dữ liệu từ FACEBOOK & INSTAGRAM (Meta Graph API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff7e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã ghi 24 post vào c:\\Users\\Admin\\Downloads\\fb_posts.csv\n",
      "Đã ghi 24 dòng count vào c:\\Users\\Admin\\Downloads\\fb_counts.csv\n"
     ]
    }
   ],
   "source": [
    "import os, csv, time, requests\n",
    "\n",
    "USER_TOKEN   = \"EAASa6oZC3IFwBPIuQoKpcWIjfavWbV4sT9uBf7afijEKvJVaEeyfZBbIpPxZBpCTPkVbfuZBOicipcEJxYznd5jtpPjaAwbhiOINbFO7FfsUNp17LmEEPGKyHPvNNZCfg6gxitLqBt3xrPRK3RjFyge5T5PDXM3FZA3gWihyY8ZCwEVEdEc49rKZAtWRYjThRxn0txZCxrutzPIIKZBPwywCivznsTnE2J5IZBpTdhx\"\n",
    "PAGE_ID      = \"178312595372256\"   # ví dụ: \"1000123456789\"\n",
    "OUT_POSTS    = r\"c:\\Users\\Admin\\Downloads\\fb_posts.csv\"\n",
    "OUT_COUNTS   = r\"c:\\Users\\Admin\\Downloads\\fb_counts.csv\"\n",
    "\n",
    "def fb_get(url, params):\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    if r.status_code >= 400:\n",
    "        try:\n",
    "            print(\"Graph error:\", r.json())\n",
    "        except Exception:\n",
    "            print(\"Raw error:\", r.text[:500])\n",
    "        r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def get_page_access_token(user_token, page_id):\n",
    "    # Lấy danh sách page mà user quản trị + page token tương ứng\n",
    "    data = fb_get(\"https://graph.facebook.com/v18.0/me/accounts\",\n",
    "                  {\"access_token\": user_token, \"limit\": 200})\n",
    "    for item in data.get(\"data\", []):\n",
    "        if str(item.get(\"id\")) == str(page_id):\n",
    "            return item.get(\"access_token\")\n",
    "    raise RuntimeError(\"Không tìm thấy PAGE_ID trong /me/accounts. Kiểm tra PAGE_ID hoặc quyền của user.\")\n",
    "\n",
    "def fetch_all(url, params):\n",
    "    while True:\n",
    "        data = fb_get(url, params)\n",
    "        for it in data.get(\"data\", []):\n",
    "            yield it\n",
    "        paging = data.get(\"paging\", {})\n",
    "        next_url = paging.get(\"next\")\n",
    "        if not next_url:\n",
    "            break\n",
    "        # next đã chứa token/tham số\n",
    "        url, params = next_url, {}\n",
    "\n",
    "def fetch_page_posts(page_id, page_token, limit=100):\n",
    "    url = f\"https://graph.facebook.com/v18.0/{page_id}/posts\"\n",
    "    params = {\n",
    "        \"fields\": \"id,message,created_time,permalink_url\",\n",
    "        \"limit\": limit,\n",
    "        \"access_token\": page_token\n",
    "    }\n",
    "    yield from fetch_all(url, params)\n",
    "\n",
    "def fetch_counts(post_id, page_token):\n",
    "    url = f\"https://graph.facebook.com/v18.0/{post_id}\"\n",
    "    params = {\n",
    "        \"fields\": \"reactions.summary(true).limit(0),comments.summary(true).limit(0)\",\n",
    "        \"access_token\": page_token\n",
    "    }\n",
    "    data = fb_get(url, params)\n",
    "    likes = (data.get(\"reactions\") or {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "    comments = (data.get(\"comments\") or {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "    return likes, comments\n",
    "\n",
    "def write_csv(path, rows, headers):\n",
    "    exists = os.path.exists(path)\n",
    "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=headers)\n",
    "        if not exists:\n",
    "            w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "# --- MAIN ---\n",
    "def main():\n",
    "    if not USER_TOKEN:\n",
    "        raise RuntimeError(\"Thiếu META_USER_TOKEN. Hãy export META_USER_TOKEN trước khi chạy.\")\n",
    "    page_token = get_page_access_token(USER_TOKEN, PAGE_ID)\n",
    "\n",
    "    # 1) Kéo post\n",
    "    posts = list(fetch_page_posts(PAGE_ID, page_token, limit=50))\n",
    "    write_csv(OUT_POSTS, posts, [\"id\",\"message\",\"created_time\",\"permalink_url\"])\n",
    "    print(f\"Đã ghi {len(posts)} post vào {OUT_POSTS}\")\n",
    "\n",
    "    # 2) Đếm like/comment cho từng post\n",
    "    rows = []\n",
    "    for p in posts:\n",
    "        pid = p.get(\"id\")\n",
    "        try:\n",
    "            likes, comments = fetch_counts(pid, page_token)\n",
    "            rows.append({\"post_id\": pid, \"likes\": likes, \"comments\": comments})\n",
    "            time.sleep(0.15)\n",
    "        except Exception as e:\n",
    "            print(\"Lỗi đếm post\", pid, e)\n",
    "    write_csv(OUT_COUNTS, rows, [\"post_id\",\"likes\",\"comments\"])\n",
    "    print(f\"Đã ghi {len(rows)} dòng count vào {OUT_COUNTS}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfbb02",
   "metadata": {},
   "source": [
    "Lấy like/comment từ URL post công khai (FB/IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f75b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://www.instagram.com/reel/DNRt3h_Bjk3/', 'likes': None, 'comments': None, 'note': 'Site không để lộ số trong HTML tĩnh. Cần cookie đăng nhập/Graph API.'}\n",
      "✅ Đã lưu 1 dòng vào C:\\Users\\Admin\\Downloads\\posts_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import json, re, csv, requests\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/115.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    # Nếu cần, mở comment và dán cookie đăng nhập của bạn:\n",
    "    # \"Cookie\": \"ds_user_id=...; sessionid=...; csrftoken=...; datr=...; ...\",\n",
    "    \"Accept-Language\": \"vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n",
    "LIKE_PATTERNS = [\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*likes?',\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*reactions?',\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*lượt\\s*thích',\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*thích',\n",
    "]\n",
    "COMMENT_PATTERNS = [\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*comments?',\n",
    "    r'(?P<num>[\\d,\\. ]+)\\s*bình\\s*luận',\n",
    "]\n",
    "\n",
    "LIKE_KEYWORDS = [\"lượt thích\", \"thích\", \"likes\", \"reactions\"]\n",
    "COMMENT_KEYWORDS = [\"bình luận\", \"comments\"]\n",
    "\n",
    "# ========== HELPERS ==========\n",
    "\n",
    "def _to_int(s: Optional[str]) -> Optional[int]:\n",
    "    \"\"\"Parse '1.2k', '3.4m', '12,345' -> int\"\"\"\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = s.strip().lower()\n",
    "\n",
    "    # 1) 1.2k / 3.4m\n",
    "    m = re.fullmatch(r'([\\d]+(?:\\.\\d+)?)([km])', s)\n",
    "    if m:\n",
    "        val = float(m.group(1))\n",
    "        unit = m.group(2)\n",
    "        return int(val * (1_000 if unit == 'k' else 1_000_000))\n",
    "\n",
    "    # 2) số nguyên có phân cách\n",
    "    s2 = re.sub(r'[\\s,]', '', s)            # bỏ space & phẩy\n",
    "    s2 = re.sub(r'\\.(?=\\d{3}(\\D|$))', '', s2)  # bỏ chấm nếu là phân cách nghìn\n",
    "    return int(s2) if re.fullmatch(r'\\d+', s2) else None\n",
    "\n",
    "def parse_jsonld_interactions(soup: BeautifulSoup) -> Tuple[Optional[int], Optional[int]]:\n",
    "    likes = comments = None\n",
    "    for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        try:\n",
    "            data = json.loads(script.string or \"\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        items = data if isinstance(data, list) else [data]\n",
    "        for it in items:\n",
    "            stats = it.get(\"interactionStatistic\") or []\n",
    "            if isinstance(stats, dict):\n",
    "                stats = [stats]\n",
    "            for st in stats:\n",
    "                itype = (st.get(\"interactionType\") or \"\")\n",
    "                count = st.get(\"userInteractionCount\")\n",
    "                if isinstance(itype, str):\n",
    "                    itype_l = itype.lower()\n",
    "                    if likes is None and \"like\" in itype_l:\n",
    "                        likes = _to_int(str(count)) if count is not None else likes\n",
    "                    if comments is None and \"comment\" in itype_l:\n",
    "                        comments = _to_int(str(count)) if count is not None else comments\n",
    "    return likes, comments\n",
    "\n",
    "def regex_text_for_counts(text: str) -> Tuple[Optional[int], Optional[int]]:\n",
    "    likes = comments = None\n",
    "    for pat in LIKE_PATTERNS:\n",
    "        m = re.search(pat, text, flags=re.I)\n",
    "        if m:\n",
    "            likes = _to_int((m.group(\"num\") or \"\").strip())\n",
    "            break\n",
    "    for pat in COMMENT_PATTERNS:\n",
    "        m = re.search(pat, text, flags=re.I)\n",
    "        if m:\n",
    "            comments = _to_int((m.group(\"num\") or \"\").strip())\n",
    "            break\n",
    "    return likes, comments\n",
    "\n",
    "def _near_keyword_number_spans(soup: BeautifulSoup,\n",
    "                               keywords: List[str]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Tìm <span> số nằm trong vùng văn bản có chứa 1 từ khóa bất kỳ.\n",
    "    Ví dụ DOM IG/FB: <span>31</span> ... \"lượt thích\"\n",
    "    \"\"\"\n",
    "    # 1) tìm các span chỉ chứa số hoặc số + k/m\n",
    "    numeric_spans = soup.find_all(\n",
    "        \"span\", string=re.compile(r\"^\\s*\\d[\\d\\.,\\s]*([km])?\\s*$\", re.I)\n",
    "    )\n",
    "    for sp in numeric_spans:\n",
    "        # gom text cha (nhiều cấp), dừng ở container vừa phải\n",
    "        parent = sp\n",
    "        hops = 0\n",
    "        found = False\n",
    "        while parent and hops < 4:\n",
    "            parent = parent.parent\n",
    "            hops += 1\n",
    "            if not parent:\n",
    "                break\n",
    "            pt = parent.get_text(\" \", strip=True).lower()\n",
    "            # nếu trong block có keyword thì lấy số\n",
    "            if any(kw in pt for kw in keywords):\n",
    "                val = _to_int(sp.get_text(strip=True))\n",
    "                if val is not None:\n",
    "                    return val\n",
    "                # nếu span là \"31\" nhưng đơn vị ở sibling, thử bắt cụm gần kề\n",
    "                sib_text = \" \".join(s.get_text(\" \", strip=True).lower()\n",
    "                                    for s in parent.find_all(\"span\"))\n",
    "                if any(kw in sib_text for kw in keywords):\n",
    "                    val = _to_int(sp.get_text(strip=True))\n",
    "                    if val is not None:\n",
    "                        return val\n",
    "    return None\n",
    "\n",
    "def parse_dom_counts(soup: BeautifulSoup) -> Tuple[Optional[int], Optional[int]]:\n",
    "    \"\"\"Chiến lược DOM: bắt số gần keywords.\"\"\"\n",
    "    likes = _near_keyword_number_spans(soup, LIKE_KEYWORDS)\n",
    "    comments = _near_keyword_number_spans(soup, COMMENT_KEYWORDS)\n",
    "    return likes, comments\n",
    "\n",
    "# ========== CORE ==========\n",
    "\n",
    "def extract_like_comment_counts(url: str) -> Dict[str, Optional[int]]:\n",
    "    r = requests.get(url, headers=HEADERS, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    likes = comments = None\n",
    "\n",
    "    # 1) JSON-LD\n",
    "    l1, c1 = parse_jsonld_interactions(soup)\n",
    "    likes = likes if likes is not None else l1\n",
    "    comments = comments if comments is not None else c1\n",
    "\n",
    "    # 2) og:description\n",
    "    if likes is None or comments is None:\n",
    "        og = soup.find(\"meta\", attrs={\"property\": \"og:description\"})\n",
    "        if og and og.get(\"content\"):\n",
    "            l2, c2 = regex_text_for_counts(og[\"content\"])\n",
    "            likes = likes if likes is not None else l2\n",
    "            comments = comments if comments is not None else c2\n",
    "\n",
    "    # 3) Regex toàn trang (fallback)\n",
    "    if likes is None or comments is None:\n",
    "        l3, c3 = regex_text_for_counts(soup.get_text(\" \", strip=True))\n",
    "        likes = likes if likes is not None else l3\n",
    "        comments = comments if comments is not None else c3\n",
    "\n",
    "    # 4) DOM số + từ khóa (mới)\n",
    "    if likes is None or comments is None:\n",
    "        l4, c4 = parse_dom_counts(soup)\n",
    "        likes = likes if likes is not None else l4\n",
    "        comments = comments if comments is not None else c4\n",
    "\n",
    "    # ghi chú lý do nếu cả 2 vẫn None (hay gặp với IG/FB ko có cookie)\n",
    "    if likes is None and comments is None:\n",
    "        host = urlparse(url).hostname or \"\"\n",
    "        note = None\n",
    "        if \"instagram.com\" in host or \"facebook.com\" in host:\n",
    "            note = \"Site không để lộ số trong HTML tĩnh. Cần cookie đăng nhập/Graph API.\"\n",
    "        else:\n",
    "            note = \"Không tìm thấy số like/comment trong HTML hoặc metadata.\"\n",
    "        return {\"url\": url, \"likes\": None, \"comments\": None, \"note\": note}\n",
    "\n",
    "    return {\"url\": url, \"likes\": likes, \"comments\": comments}\n",
    "\n",
    "def save_to_csv(results: List[Dict], filename: str = \"fb_ig_posts.csv\") -> None:\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        fieldnames = [\"url\", \"likes\", \"comments\", \"note\"]\n",
    "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        for row in results:\n",
    "            if \"note\" not in row:\n",
    "                row[\"note\"] = \"\"\n",
    "            w.writerow(row)\n",
    "    print(f\"✅ Đã lưu {len(results)} dòng vào {filename}\")\n",
    "\n",
    "# ========== CLI DEMO ==========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = [\n",
    "        # Ví dụ IG (cần cookie đăng nhập để có HTML đầy đủ)\n",
    "        \"https://www.instagram.com/reel/DNRt3h_Bjk3/\",\n",
    "        # Thêm các URL FB/IG công khai khác...\n",
    "    ]\n",
    "    results = [extract_like_comment_counts(u) for u in urls]\n",
    "\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "    # Xuất CSV\n",
    "    save_to_csv(results, r\"C:\\Users\\Admin\\Downloads\\posts_stats.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
